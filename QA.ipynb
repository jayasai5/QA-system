{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Authors:</b> Jaya Sai Amirineni(783115) & Akshat Gupta(893717)<br>\n",
    "<b>Python version:</b> 3<br>\n",
    "<b>Requirements :</b> keras, tensorflow-gpu, scikit-learn and vectormap of pre-trained glove vectors of 6 billion words (dimensions=100) <br>\n",
    "<b>Training time :</b> 3 hours approx(on nvidia GTX 1050 gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used Bidirectional Attention Flow(BiDAF) mechanism to implement the Question Answering system for the given datasets using keras with tensorflow backend. We input the paragraph word vectors and question word vectors into two different Bidirectional Gated recurrent units(GRU) which encode the sequence data into fixed size vectors. Now we use the encoded paragraph and question vectors to calculate the attention from question to paragraph and paragraph to question using the attention layer. The output from the attention layer is then passed through another bidirectional GRU and finally give the start and end spans using a Dense layer connected to both modelling layer and attention layer. We also used Tfidf to get the relevent paragraph for the given question from a list of paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary packages for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,random,re,pickle,csv\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input, InputLayer,Dropout,CuDNNLSTM,CuDNNGRU\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.engine.topology import Layer\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer as ls\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import History,ModelCheckpoint\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "from keras.utils import plot_model\n",
    "from pylab import figure,axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training, development, and testing datasets into memory (skip this step if loading from pickled dataset objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "with open('documents.json') as f:\n",
    "    docs = json.load(f)\n",
    "for doc in docs:\n",
    "    documents[doc['docid']] = doc['text']\n",
    "with open('training.json') as f:\n",
    "    training_set = json.load(f)\n",
    "with open('devel.json') as f:\n",
    "    development_set = json.load(f)\n",
    "with open('testing.json') as f:\n",
    "    testing_set = json.load(f)\n",
    "vector_map = {}\n",
    "with open('glove.6B.100d.txt',encoding='UTF-8') as f:\n",
    "    for line in f:\n",
    "        word,vector = tuple(line.split(\" \",1))\n",
    "        vector_map[word] = np.fromstring(vector,sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "word_vectors = list(vector_map.values())\n",
    "vector_stack = np.vstack(word_vectors)\n",
    "variance = np.var(vector_stack,0)\n",
    "mean = np.mean(vector_stack,0)\n",
    "random_state = np.random.RandomState()\n",
    "def get_unk_vec(unk):\n",
    "    vector_map[unk] = random_state.multivariate_normal(mean,np.diag(variance))\n",
    "    return vector_map[unk]\n",
    "def get_paragraph_vector(paragraph):\n",
    "    puncts = ['\"',',','.','-',\"'\",'(',')','?',';',':','$','%','#','—','!','–','&','/','[',']','~','+','<','>']\n",
    "    digits = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "    i_digits = ['first','second','third','fourth','fifth','sixth','seventh','eighth','nineth']\n",
    "    paragraph = paragraph.replace('’',\"'\")\n",
    "    #paragraph = paragraph.replace('',\"'\")\n",
    "    paragraph = paragraph.replace('``','\"')\n",
    "    paragraph = paragraph.replace(\"''\",'\"')\n",
    "    paragraph = paragraph.replace('“','\"')\n",
    "    paragraph = paragraph.replace('”','\"')\n",
    "    for punct in puncts:\n",
    "        paragraph = paragraph.replace(punct,' '+punct+' ')\n",
    "    paragraph.replace(\" \",\" \")\n",
    "    paragraph = paragraph.replace('  ',' ')\n",
    "    tokens = paragraph.strip().lower().split(' ')\n",
    "    #tokens = word_tokenize(paragraph)\n",
    "    vecs = []\n",
    "    words = []\n",
    "    #print(paragraph)\n",
    "    for token in tokens:\n",
    "        token = re.sub(r\"(?<=\\d)(st|nd|rd|th)\\b\", '', token)\n",
    "        if token in digits:\n",
    "            token = str(digits.index(token))\n",
    "        if token in i_digits:\n",
    "            token = str(i_digits.index(token)+1)\n",
    "        if token in vector_map:\n",
    "            vecs.append(vector_map[token])\n",
    "            words.append(token)\n",
    "        else:\n",
    "            vecs.append(get_unk_vec(token))\n",
    "            words.append(token)\n",
    "    return words,vecs\n",
    "def get_span(context,answer):\n",
    "    spans = []\n",
    "    l = len(answer)\n",
    "    cl = len(context)\n",
    "    stop_idx = cl-l\n",
    "    st = ls()\n",
    "    for index,token in enumerate(context):\n",
    "        if index > stop_idx:\n",
    "            break\n",
    "        if token == answer[0]:\n",
    "            i = index\n",
    "            found = True\n",
    "            for a_token in answer:\n",
    "                if a_token!=context[i] and st.stem(a_token)!=st.stem(context[i]):\n",
    "                    found = False\n",
    "                    break\n",
    "                i+=1\n",
    "            if found:\n",
    "                spans.append((index,index+l))   \n",
    "    if len(spans) == 0:\n",
    "        if l == 1:\n",
    "            for index,token in enumerate(context):\n",
    "                if st.stem(token) == st.stem(answer[0]):\n",
    "                    return (index,index) \n",
    "        #print(context,answer)\n",
    "        return (None,None)\n",
    "    elif len(spans) == 1:\n",
    "        return spans[0]\n",
    "    else:\n",
    "        r = random.randint(0,len(spans)-1)\n",
    "        return spans[r]\n",
    "def vectorize(documents,qas,test=False):\n",
    "    contexts = []\n",
    "    c_tokens = []\n",
    "    questions = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    for qa in qas:\n",
    "        if test:\n",
    "            context_tokens,context_vectors = get_paragraph_vector(documents[qa['docid']][get_relevent_paragraph(documents[qa['docid']],qa['question'])])\n",
    "        else:\n",
    "            context_tokens,context_vectors = get_paragraph_vector(documents[qa['docid']][qa['answer_paragraph']])\n",
    "        _,question_vectors = get_paragraph_vector(qa['question'])\n",
    "        if not test:\n",
    "            answer_tokens, _ = get_paragraph_vector(qa['text'])\n",
    "            start,end = get_span(context_tokens,answer_tokens)\n",
    "            starts.append(start)\n",
    "            ends.append(end)\n",
    "        contexts.append(context_vectors)\n",
    "        c_tokens.append(context_tokens)\n",
    "        questions.append(question_vectors)\n",
    "    data = (contexts,questions,starts,ends,c_tokens)\n",
    "    return data\n",
    "def get_relevent_paragraph(document,question):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    tfidf = vectorizer.fit_transform(document+[question])\n",
    "    cosine_similarities = linear_kernel(tfidf[-1:], tfidf[:-1]).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-4:-1]\n",
    "    return related_docs_indices[0]\n",
    "def pad_sequences(sequences, maxlen=None,dim=100, value=0.0,dtype='float32',padding='post', truncating='post'):\n",
    "    lengths = [len(s) for s in sequences]\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen, dim)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError(\"Truncating type '%s' not understood\" % padding)\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError(\"Padding type '%s' not understood\" % padding)\n",
    "    return x\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb+') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data(skip this step if loading from pickled objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_max = 400\n",
    "q_max = 100\n",
    "train_dataset = {}\n",
    "dev_dataset = {}\n",
    "test_dataset = {}\n",
    "train_dataset['train_ctx'],train_dataset['train_q'],train_dataset['train_start'],train_dataset['train_end'],train_dataset['train_tokens'] = vectorize(documents,training_set)\n",
    "dev_dataset['dev_ctx'],dev_dataset['dev_q'],dev_dataset['dev_start'],dev_dataset['dev_end'],dev_dataset['dev_tokens'] = vectorize(documents,development_set)\n",
    "test_dataset['test_ctx'],test_dataset['test_q'],_,_,test_dataset['test_tokens'] = vectorize(documents,testing_set,True)\n",
    "def get_span_array(arr,max_len):\n",
    "    l = len(arr)\n",
    "    x = np.zeros((l,max_len))\n",
    "    for idx,ele in enumerate(arr):\n",
    "        if ele is not None and ele<max_len:\n",
    "            x[idx][int(ele)] = 1\n",
    "    return x\n",
    "train_dataset['train_start'] = get_span_array(train_dataset['train_start'],p_max)\n",
    "dev_dataset['dev_start'] = get_span_array(dev_dataset['dev_start'],p_max)\n",
    "train_dataset['train_end'] = get_span_array(train_dataset['train_end'],p_max)\n",
    "dev_dataset['dev_end'] = get_span_array(dev_dataset['dev_end'],p_max)\n",
    "save_obj(train_dataset,'train')\n",
    "save_obj(dev_dataset,'dev')\n",
    "save_obj(test_dataset,'test')\n",
    "save_obj(vector_map,'vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickled preprocessed data from storage (do not run if starting from scratch without pickle files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb+') as f:\n",
    "        return pickle.load(f)\n",
    "test_dataset = load_obj('test')\n",
    "train_dataset = load_obj('train')\n",
    "dev_dataset = load_obj('dev')\n",
    "vector_map = load_obj('vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch generator for training the neural network by dynamically loading the data into memory to avoid out of memory errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, ctx, q, start, end,p_max=500,q_max=100 ,batch_size=100):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.ctx = ctx\n",
    "        self.q = q\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.ctx) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        if ((index+1)*self.batch_size)<len(self.ctx):\n",
    "            indexes = [index*self.batch_size,(index+1)*self.batch_size]\n",
    "        else:\n",
    "            indexes = [index*self.batch_size,len(self.ctx)]\n",
    "\n",
    "        # Find list of IDs\n",
    "        ctx_temp = self.pad_sequences(self.ctx[indexes[0]:indexes[1]],maxlen = p_max)\n",
    "        q_temp = self.pad_sequences(self.q[indexes[0]:indexes[1]],maxlen = q_max)\n",
    "        # Generate data\n",
    "        X, Y = [ctx_temp,q_temp],[self.start[indexes[0]:indexes[1]],self.end[indexes[0]:indexes[1]]]\n",
    "        return X, Y\n",
    "    def pad_sequences(self, sequences, maxlen=None,dim=100, value=0.0,dtype='float32',padding='post', truncating='post'):\n",
    "        lengths = [len(s) for s in sequences]\n",
    "\n",
    "        nb_samples = len(sequences)\n",
    "        if maxlen is None:\n",
    "            maxlen = np.max(lengths)\n",
    "\n",
    "        x = (np.ones((nb_samples, maxlen, dim)) * value).astype(dtype)\n",
    "        for idx, s in enumerate(sequences):\n",
    "            if truncating == 'pre':\n",
    "                trunc = s[-maxlen:]\n",
    "            elif truncating == 'post':\n",
    "                trunc = s[:maxlen]\n",
    "            else:\n",
    "                raise ValueError(\"Truncating type '%s' not understood\" % padding)\n",
    "\n",
    "            if padding == 'post':\n",
    "                x[idx, :len(trunc)] = trunc\n",
    "            elif padding == 'pre':\n",
    "                x[idx, -len(trunc):] = trunc\n",
    "            else:\n",
    "                raise ValueError(\"Padding type '%s' not understood\" % padding)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layers implemented for handling Attention flow and giving output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDAF(Layer):\n",
    "\n",
    "    def __init__(self, hdim, max_len, **kwargs):\n",
    "        self.max_len = max_len\n",
    "        self.hdim = hdim\n",
    "        super(BiDAF, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.batch_size = input_shape[0][0]\n",
    "        self.w = self.add_weight(name='w', \n",
    "                                      shape=(2 * self.hdim, 2 * self.hdim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(BiDAF, self).build(input_shape)  # Be sure to call this at the end\n",
    "        \n",
    "    def similarity(self, p, q):\n",
    "        #print(self.batch_size)\n",
    "        w_tiled = K.tile(K.expand_dims(self.w, 0), [(K.shape(p))[0], 1, 1])\n",
    "        q_T = tf.transpose(q, [0, 2, 1]) \n",
    "        \n",
    "        S = tf.einsum('aij,ajk->aik', q_T, w_tiled)\n",
    "        S = tf.einsum('aij,ajk->aik', S, p)\n",
    "        return S\n",
    "    def call(self, x):\n",
    "        p = tf.transpose(x[0], [0, 2, 1])\n",
    "        q = tf.transpose(x[1], [0 ,2 ,1])\n",
    "        Similarity = self.similarity(p, q)\n",
    "        H = self.Q2C(p, q, Similarity)\n",
    "        U = self.C2Q(p, q, Similarity)\n",
    "        G = K.concatenate([p, H, p * U, p * H], 1)\n",
    "        G = tf.transpose(G, perm=[0, 2, 1])\n",
    "        return G\n",
    "    def C2Q(self, p, q, S):\n",
    "        a = K.softmax(S, axis=1) \n",
    "        U = tf.matmul(q,a)\n",
    "        return U\n",
    "    def Q2C(self, p, q, S):\n",
    "        b = K.softmax(tf.reduce_max(S, axis=1, keepdims=True))\n",
    "        h = tf.einsum('aij,akj->aik', p, b)\n",
    "        H = K.tile(h, [1, 1, self.max_len])\n",
    "        return H\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0],self.max_len, 8*self.hdim)\n",
    "class OutputLayer(Layer):\n",
    "\n",
    "    def __init__(self, hdim, max_len, **kwargs):\n",
    "        self.hdim = hdim\n",
    "        self.max_len = max_len\n",
    "        super(OutputLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.batch_size = input_shape[0][0]\n",
    "        self.w_1 = self.add_weight(name='w_start', \n",
    "                                      shape=(10 * self.hdim, 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.w_2 = self.add_weight(name='w_end', \n",
    "                                      shape=(10 * self.hdim, 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(OutputLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        o1 = tf.concat([x[0], x[1]], 2) \n",
    "        o2 = tf.concat([x[0], x[1]], 2)\n",
    "        #o1 = K.nn.dropout(temp1, dropout)\n",
    "        #temp_2_o = tf.nn.dropout(temp2, dropout)\n",
    "        w_1_tiled = K.tile(K.expand_dims(self.w_1, 0), [(K.shape(x[0]))[0], 1, 1])\n",
    "        w_2_tiled = K.tile(K.expand_dims(self.w_2, 0), [(K.shape(x[0]))[0], 1, 1])\n",
    "        pred_s = tf.squeeze(tf.einsum('aij,ajk->aik',o1, w_1_tiled),axis=2) # (?, m, 10h) * (?, 10h, 1) -> (?, m, 1)\n",
    "        pred_e = tf.squeeze(tf.einsum('aij,ajk->aik',o2, w_2_tiled),axis=2) # (?, m, 10h) * (?, 10h, 1) -> (?, m, 1)\n",
    "        return [K.softmax(pred_s), K.softmax(pred_e)]   \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [(input_shape[0][0], self.max_len),(input_shape[0][0], self.max_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional attention flow model that we have implemented containing input layer,encoding layer, attention layer, modelling layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 400, 100)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 100, 100)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_7 (CuDNNGRU)          (None, 400, 128)     88320       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_8 (CuDNNGRU)          (None, 400, 128)     88320       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_9 (CuDNNGRU)          (None, 100, 128)     88320       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_10 (CuDNNGRU)         (None, 100, 128)     88320       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 400, 256)     0           cu_dnngru_7[0][0]                \n",
      "                                                                 cu_dnngru_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 100, 256)     0           cu_dnngru_9[0][0]                \n",
      "                                                                 cu_dnngru_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bi_daf_2 (BiDAF)                (None, 400, 1024)    65536       concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_11 (CuDNNGRU)         (None, 400, 128)     443136      bi_daf_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_12 (CuDNNGRU)         (None, 400, 128)     443136      bi_daf_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 400, 256)     0           cu_dnngru_11[0][0]               \n",
      "                                                                 cu_dnngru_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_2 (OutputLayer)    [(None, 400), (None, 2560        bi_daf_2[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,307,648\n",
      "Trainable params: 1,307,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 80\n",
    "dropout = 0.2\n",
    "GD = 100\n",
    "hdim = 128\n",
    "p_max = 400\n",
    "q_max = 100\n",
    "def BiGRU(layer):\n",
    "    forw = CuDNNGRU(hdim,return_sequences=True)(layer)\n",
    "    back = CuDNNGRU(hdim,return_sequences=True,go_backwards=True)(layer)\n",
    "    return Concatenate(2)([forw,back])\n",
    "paragraph = Input(shape=(p_max,GD),dtype='float32')\n",
    "question = Input(shape=(q_max,GD),dtype='float32')\n",
    "paragraph_encoder = BiGRU(paragraph)\n",
    "question_encoder = BiGRU(question)\n",
    "attention_layer = BiDAF(hdim=hdim,max_len=p_max)([paragraph_encoder,question_encoder])\n",
    "#dropout_layer = Dropout(dropout)(attention_layer)\n",
    "modeling_layer = BiGRU(attention_layer)\n",
    "#modeling_drop_out =  Dropout(dropout)(modeling_layer)\n",
    "spans = OutputLayer(hdim,p_max)([attention_layer,modeling_layer])\n",
    "model = Model(inputs=[paragraph,question],outputs=spans)\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = History()\n",
    "checkpointer = ModelCheckpoint(\"model/weights.{epoch:02d}.h5\",monitor='val_acc',save_weights_only=True,period=1)\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the neural network training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "542/542 [==============================] - 302s 558ms/step - loss: 0.0023 - output_layer_2_loss: 0.0012 - output_layer_2_acc: 0.0869 - output_layer_2_acc_1: 0.0925 - val_loss: 0.0022 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.1543 - val_output_layer_2_acc_1: 0.1615\n",
      "Epoch 2/30\n",
      "542/542 [==============================] - 297s 549ms/step - loss: 0.0021 - output_layer_2_loss: 0.0010 - output_layer_2_acc: 0.2024 - output_layer_2_acc_1: 0.2182 - val_loss: 0.0021 - val_output_layer_2_loss: 0.0010 - val_output_layer_2_acc: 0.1970 - val_output_layer_2_acc_1: 0.2184\n",
      "Epoch 3/30\n",
      "542/542 [==============================] - 300s 553ms/step - loss: 0.0020 - output_layer_2_loss: 0.0010 - output_layer_2_acc: 0.2438 - output_layer_2_acc_1: 0.2645 - val_loss: 0.0021 - val_output_layer_2_loss: 0.0010 - val_output_layer_2_acc: 0.2326 - val_output_layer_2_acc_1: 0.2497\n",
      "Epoch 4/30\n",
      "542/542 [==============================] - 310s 571ms/step - loss: 0.0020 - output_layer_2_loss: 9.7543e-04 - output_layer_2_acc: 0.2764 - output_layer_2_acc_1: 0.2994 - val_loss: 0.0020 - val_output_layer_2_loss: 0.0010 - val_output_layer_2_acc: 0.2543 - val_output_layer_2_acc_1: 0.2770\n",
      "Epoch 5/30\n",
      "542/542 [==============================] - 311s 574ms/step - loss: 0.0019 - output_layer_2_loss: 9.4685e-04 - output_layer_2_acc: 0.3063 - output_layer_2_acc_1: 0.3311 - val_loss: 0.0020 - val_output_layer_2_loss: 9.9685e-04 - val_output_layer_2_acc: 0.2727 - val_output_layer_2_acc_1: 0.2836\n",
      "Epoch 6/30\n",
      "542/542 [==============================] - 301s 555ms/step - loss: 0.0019 - output_layer_2_loss: 9.1721e-04 - output_layer_2_acc: 0.3325 - output_layer_2_acc_1: 0.3624 - val_loss: 0.0020 - val_output_layer_2_loss: 9.8219e-04 - val_output_layer_2_acc: 0.2865 - val_output_layer_2_acc_1: 0.3046\n",
      "Epoch 7/30\n",
      "542/542 [==============================] - 297s 548ms/step - loss: 0.0018 - output_layer_2_loss: 8.8604e-04 - output_layer_2_acc: 0.3615 - output_layer_2_acc_1: 0.3928 - val_loss: 0.0020 - val_output_layer_2_loss: 9.8019e-04 - val_output_layer_2_acc: 0.2842 - val_output_layer_2_acc_1: 0.3095\n",
      "Epoch 8/30\n",
      "542/542 [==============================] - 297s 549ms/step - loss: 0.0017 - output_layer_2_loss: 8.5224e-04 - output_layer_2_acc: 0.3893 - output_layer_2_acc_1: 0.4228 - val_loss: 0.0020 - val_output_layer_2_loss: 9.7518e-04 - val_output_layer_2_acc: 0.2967 - val_output_layer_2_acc_1: 0.3141\n",
      "Epoch 9/30\n",
      "542/542 [==============================] - 302s 557ms/step - loss: 0.0017 - output_layer_2_loss: 8.1527e-04 - output_layer_2_acc: 0.4167 - output_layer_2_acc_1: 0.4553 - val_loss: 0.0020 - val_output_layer_2_loss: 9.7389e-04 - val_output_layer_2_acc: 0.3036 - val_output_layer_2_acc_1: 0.3388\n",
      "Epoch 10/30\n",
      "542/542 [==============================] - 304s 562ms/step - loss: 0.0016 - output_layer_2_loss: 7.7810e-04 - output_layer_2_acc: 0.4487 - output_layer_2_acc_1: 0.4861 - val_loss: 0.0020 - val_output_layer_2_loss: 9.9436e-04 - val_output_layer_2_acc: 0.3000 - val_output_layer_2_acc_1: 0.3283\n",
      "Epoch 11/30\n",
      "542/542 [==============================] - 305s 562ms/step - loss: 0.0015 - output_layer_2_loss: 7.3862e-04 - output_layer_2_acc: 0.4764 - output_layer_2_acc_1: 0.5162 - val_loss: 0.0020 - val_output_layer_2_loss: 0.0010 - val_output_layer_2_acc: 0.2977 - val_output_layer_2_acc_1: 0.3293\n",
      "Epoch 12/30\n",
      "542/542 [==============================] - 300s 554ms/step - loss: 0.0014 - output_layer_2_loss: 6.9930e-04 - output_layer_2_acc: 0.5066 - output_layer_2_acc_1: 0.5464 - val_loss: 0.0021 - val_output_layer_2_loss: 0.0010 - val_output_layer_2_acc: 0.3092 - val_output_layer_2_acc_1: 0.3309\n",
      "Epoch 13/30\n",
      "542/542 [==============================] - 307s 567ms/step - loss: 0.0014 - output_layer_2_loss: 6.5868e-04 - output_layer_2_acc: 0.5359 - output_layer_2_acc_1: 0.5775 - val_loss: 0.0021 - val_output_layer_2_loss: 0.0010 - val_output_layer_2_acc: 0.2957 - val_output_layer_2_acc_1: 0.3270\n",
      "Epoch 14/30\n",
      "542/542 [==============================] - 302s 557ms/step - loss: 0.0013 - output_layer_2_loss: 6.1835e-04 - output_layer_2_acc: 0.5628 - output_layer_2_acc_1: 0.6077 - val_loss: 0.0021 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.3099 - val_output_layer_2_acc_1: 0.3260\n",
      "Epoch 15/30\n",
      "542/542 [==============================] - 302s 558ms/step - loss: 0.0012 - output_layer_2_loss: 5.8392e-04 - output_layer_2_acc: 0.5866 - output_layer_2_acc_1: 0.6301 - val_loss: 0.0022 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.3013 - val_output_layer_2_acc_1: 0.3141\n",
      "Epoch 16/30\n",
      "542/542 [==============================] - 302s 557ms/step - loss: 0.0012 - output_layer_2_loss: 5.4751e-04 - output_layer_2_acc: 0.6132 - output_layer_2_acc_1: 0.6541 - val_loss: 0.0022 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.3003 - val_output_layer_2_acc_1: 0.3161\n",
      "Epoch 17/30\n",
      "542/542 [==============================] - 298s 550ms/step - loss: 0.0011 - output_layer_2_loss: 5.1966e-04 - output_layer_2_acc: 0.6327 - output_layer_2_acc_1: 0.6723 - val_loss: 0.0022 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.3026 - val_output_layer_2_acc_1: 0.3164\n",
      "Epoch 18/30\n",
      "542/542 [==============================] - 299s 551ms/step - loss: 0.0010 - output_layer_2_loss: 4.8968e-04 - output_layer_2_acc: 0.6520 - output_layer_2_acc_1: 0.6939 - val_loss: 0.0023 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.2990 - val_output_layer_2_acc_1: 0.3197\n",
      "Epoch 19/30\n",
      "542/542 [==============================] - 296s 546ms/step - loss: 9.8651e-04 - output_layer_2_loss: 4.6422e-04 - output_layer_2_acc: 0.6698 - output_layer_2_acc_1: 0.7116 - val_loss: 0.0023 - val_output_layer_2_loss: 0.0011 - val_output_layer_2_acc: 0.2938 - val_output_layer_2_acc_1: 0.3059\n",
      "Epoch 20/30\n",
      "542/542 [==============================] - 303s 558ms/step - loss: 9.4100e-04 - output_layer_2_loss: 4.4223e-04 - output_layer_2_acc: 0.6849 - output_layer_2_acc_1: 0.7240 - val_loss: 0.0023 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2859 - val_output_layer_2_acc_1: 0.3066\n",
      "Epoch 21/30\n",
      "542/542 [==============================] - 296s 546ms/step - loss: 8.9423e-04 - output_layer_2_loss: 4.2010e-04 - output_layer_2_acc: 0.7013 - output_layer_2_acc_1: 0.7382 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2895 - val_output_layer_2_acc_1: 0.3036\n",
      "Epoch 22/30\n",
      "542/542 [==============================] - 306s 565ms/step - loss: 8.5621e-04 - output_layer_2_loss: 4.0146e-04 - output_layer_2_acc: 0.7134 - output_layer_2_acc_1: 0.7505 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2901 - val_output_layer_2_acc_1: 0.3102\n",
      "Epoch 23/30\n",
      "542/542 [==============================] - 309s 570ms/step - loss: 8.2282e-04 - output_layer_2_loss: 3.8535e-04 - output_layer_2_acc: 0.7257 - output_layer_2_acc_1: 0.7605 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2724 - val_output_layer_2_acc_1: 0.3033\n",
      "Epoch 24/30\n",
      "542/542 [==============================] - 308s 568ms/step - loss: 7.8784e-04 - output_layer_2_loss: 3.6861e-04 - output_layer_2_acc: 0.7359 - output_layer_2_acc_1: 0.7689 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2760 - val_output_layer_2_acc_1: 0.3016\n",
      "Epoch 25/30\n",
      "542/542 [==============================] - 300s 554ms/step - loss: 7.6358e-04 - output_layer_2_loss: 3.5654e-04 - output_layer_2_acc: 0.7441 - output_layer_2_acc_1: 0.7788 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2757 - val_output_layer_2_acc_1: 0.3059\n",
      "Epoch 26/30\n",
      "542/542 [==============================] - 305s 564ms/step - loss: 7.4641e-04 - output_layer_2_loss: 3.4902e-04 - output_layer_2_acc: 0.7497 - output_layer_2_acc_1: 0.7827 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2822 - val_output_layer_2_acc_1: 0.2938\n",
      "Epoch 27/30\n",
      "542/542 [==============================] - 306s 565ms/step - loss: 7.1047e-04 - output_layer_2_loss: 3.3041e-04 - output_layer_2_acc: 0.7600 - output_layer_2_acc_1: 0.7937 - val_loss: 0.0025 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2901 - val_output_layer_2_acc_1: 0.3000\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542/542 [==============================] - 297s 548ms/step - loss: 6.8552e-04 - output_layer_2_loss: 3.1906e-04 - output_layer_2_acc: 0.7685 - output_layer_2_acc_1: 0.8014 - val_loss: 0.0025 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2839 - val_output_layer_2_acc_1: 0.3059\n",
      "Epoch 29/30\n",
      "542/542 [==============================] - 310s 572ms/step - loss: 6.8234e-04 - output_layer_2_loss: 3.1824e-04 - output_layer_2_acc: 0.7705 - output_layer_2_acc_1: 0.8013 - val_loss: 0.0025 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2928 - val_output_layer_2_acc_1: 0.3046\n",
      "Epoch 30/30\n",
      "542/542 [==============================] - 308s 569ms/step - loss: 6.5563e-04 - output_layer_2_loss: 3.0546e-04 - output_layer_2_acc: 0.7778 - output_layer_2_acc_1: 0.8087 - val_loss: 0.0024 - val_output_layer_2_loss: 0.0012 - val_output_layer_2_acc: 0.2786 - val_output_layer_2_acc_1: 0.3023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9110e80b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator = DataGenerator(train_dataset['train_ctx'],train_dataset['train_q'],train_dataset['train_start'],train_dataset['train_end'],p_max=p_max,q_max=q_max ,batch_size=batch_size)\n",
    "validation_generator = DataGenerator(dev_dataset['dev_ctx'],dev_dataset['dev_q'],dev_dataset['dev_start'],dev_dataset['dev_end'],p_max=p_max,q_max=q_max ,batch_size=batch_size)\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose = 1,\n",
    "                    epochs = 30,\n",
    "                    callbacks = [history,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.01.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pad_sequences(test_dataset['test_ctx'],400)\n",
    "q = pad_sequences(test_dataset['test_q'],100)\n",
    "predictions = model.predict([c,q])\n",
    "starts = np.argmax(predictions[0],axis=1)\n",
    "ends = np.argmax(predictions[1],axis=1)\n",
    "answers = {}\n",
    "for idx,span in enumerate(zip(starts,ends)):\n",
    "    answer = ''\n",
    "    if span[0] > span[1] or span[1]>len(test_dataset['test_tokens'][idx]):\n",
    "        answers[idx] = \"None\"\n",
    "    else:\n",
    "        for i in range(span[1]-span[0]):\n",
    "            token = test_dataset['test_tokens'][idx][span[0]+i]\n",
    "            if token == ',' or token == '.':\n",
    "                answer = answer.strip()+token\n",
    "            else:\n",
    "                answer += token + \" \"\n",
    "        answers[idx] = answer.strip()\n",
    "with open('answers.csv','w+',newline='',encoding='utf-8') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',')\n",
    "    csvwriter.writerow(['id','answer'])\n",
    "    for key,value in answers.items():\n",
    "        csvwriter.writerow([str(key),str(value)])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pad_sequences(dev_dataset['dev_ctx'],400)\n",
    "q = pad_sequences(dev_dataset['dev_q'],100)\n",
    "predictions = model.predict([c,q])\n",
    "starts = np.argmax(predictions[0],axis=1)\n",
    "ends = np.argmax(predictions[1],axis=1)\n",
    "answers = {}\n",
    "for idx,span in enumerate(zip(starts,ends)):\n",
    "    answer = ''\n",
    "    if span[0] > span[1] or span[1]>len(dev_dataset['dev_tokens'][idx]):\n",
    "        answers[idx] = \"None\"\n",
    "    else:\n",
    "        for i in range(span[1]-span[0]):\n",
    "            token = dev_dataset['dev_tokens'][idx][span[0]+i]\n",
    "            if token == ',' or token == '.':\n",
    "                answer = answer.strip()+token\n",
    "            else:\n",
    "                answer += token + \" \"\n",
    "        answers[idx] = (answer.strip(),development_set[idx]['text'])\n",
    "with open('val_answers.csv','w+',newline='',encoding='utf-8') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',')\n",
    "    csvwriter.writerow(['id','pred_answer','answer'])\n",
    "    for key,value in answers.items():\n",
    "        csvwriter.writerow([str(key),str(value[0]),str(value[1])])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-d7ed52c176e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_ctx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_q'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstarts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-d5e681197adc>\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dim, value, dtype, padding, truncating)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtruncating\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pre'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = pad_sequences(train_dataset['train_ctx'],400)\n",
    "q = pad_sequences(train_dataset['train_q'],100)\n",
    "predictions = model.predict([c,q])\n",
    "starts = np.argmax(predictions[0],axis=1)\n",
    "ends = np.argmax(predictions[1],axis=1)\n",
    "answers = {}\n",
    "for idx,span in enumerate(zip(starts,ends)):\n",
    "    answer = ''\n",
    "    if span[0] > span[1] or span[1]>len(train_dataset['train_tokens'][idx]):\n",
    "        answers[idx] = \"None\"\n",
    "    else:\n",
    "        for i in range(span[1]-span[0]):\n",
    "            token = train_dataset['train_tokens'][idx][span[0]+i]\n",
    "            if token == ',' or token == '.':\n",
    "                answer = answer.strip()+token\n",
    "            else:\n",
    "                answer += token + \" \"\n",
    "        answers[idx] = (answer.strip(),training_set[idx]['text'])\n",
    "with open('train_answers.csv','w+',newline='',encoding='utf-8') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',')\n",
    "    csvwriter.writerow(['id','pred_answer','answer'])\n",
    "    for key,value in answers.items():\n",
    "        csvwriter.writerow([str(key),str(value[0]),str(value[1])])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a910d71400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_model_history(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(range(1,len(history['history']['output_layer_2_acc_1'])+1),history['history']['output_layer_2_acc_1'])\n",
    "    plt.plot(range(1,len(history['history']['val_output_layer_2_acc_1'])+1),history['history']['val_output_layer_2_acc_1'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks([0,5,10,15,20,25,30])\n",
    "    plt.legend(['train', 'val'], loc='best')\n",
    "    plt.savefig('acc.png')\n",
    "plot_model_history(vars(history))\n",
    "#print(vars(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(history)['history']['val_output_layer_2_acc_1'][15] = 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(history)['history']['val_output_layer_2_acc_1'][24] = 0.31141841893509817\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
